{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ECBM E4040 - Assignment 2- Task 5: Kaggle Open-ended Competition\n",
    "\n",
    "Kaggle is a platform for predictive modelling and analytics competitions in which companies and researchers post data and statisticians and data miners compete to produce the best models for predicting and describing the data.\n",
    "\n",
    "1. Train a custom model for the bottle dataset classification problem. You are free to use any methods taught in the class or found by yourself on the Internet (ALWAYS provide reference to the source). General training methods include:\n",
    "    * Dropout\n",
    "    * Batch normalization\n",
    "    * Early stopping\n",
    "    * l1-norm & l2-norm penalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train your model here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import os\n",
    "from scipy.misc import imresize\n",
    "\n",
    "train_path = os.getcwd() + '/data/train_128'\n",
    "test_path = os.getcwd() + '/data/test_128'\n",
    "\n",
    "y_train = []\n",
    "X_train = []\n",
    "\n",
    "for folder in os.listdir(train_path):\n",
    "    train_sub_path = train_path + '/' + folder\n",
    "    y_value = int(folder)\n",
    "    \n",
    "    for file in os.listdir(train_sub_path):\n",
    "        file_path = train_sub_path + '/' + file\n",
    "        img = Image.open(file_path)\n",
    "        X_train.append(imresize(np.array(img), (32,32,3)))\n",
    "        y_train.append(y_value)\n",
    "        \n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "num_training = 13500\n",
    "num_validation = 1500\n",
    "\n",
    "rand_ind = np.random.choice(X_train.shape[0], num_training, replace=False)\n",
    "X_train_rn = X_train[rand_ind]\n",
    "y_train_rn = y_train[rand_ind]\n",
    "\n",
    "non_rand = np.array(list(set(range(X_train.shape[0]))-set(rand_ind)))\n",
    "X_val_rn = X_train[non_rand]\n",
    "y_val_rn = y_train[non_rand]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building my LeNet. Parameters: \n",
      "conv_featmap=[256, 64]\n",
      "fc_units=[1024]\n",
      "conv_kernel_size=[5, 5]\n",
      "pooling_size=[2, 2]\n",
      "l2_norm=0.01\n",
      "seed=235\n",
      "learning_rate=0.001\n",
      "number of batches for training: 55\n",
      "0.001\n",
      "epoch 1 \n",
      "epoch 2 \n",
      "Best validation accuracy! iteration:100 accuracy: 71.66666666666667%\n",
      "epoch 3 \n",
      "epoch 4 \n",
      "Best validation accuracy! iteration:200 accuracy: 74.86666666666667%\n",
      "epoch 5 \n",
      "epoch 6 \n",
      "Best validation accuracy! iteration:300 accuracy: 77.06666666666666%\n",
      "epoch 7 \n",
      "epoch 8 \n",
      "Best validation accuracy! iteration:400 accuracy: 77.66666666666667%\n",
      "epoch 9 \n",
      "epoch 10 \n",
      "Best validation accuracy! iteration:500 accuracy: 78.26666666666667%\n",
      "epoch 11 \n",
      "Best validation accuracy! iteration:600 accuracy: 79.33333333333333%\n",
      "epoch 12 \n",
      "epoch 13 \n",
      "Best validation accuracy! iteration:700 accuracy: 80.66666666666667%\n",
      "epoch 14 \n",
      "epoch 15 \n",
      "Best validation accuracy! iteration:800 accuracy: 82.0%\n",
      "epoch 16 \n",
      "epoch 17 \n",
      "epoch 18 \n",
      "epoch 19 \n",
      "epoch 20 \n",
      "Traning ends. The best valid accuracy is 82.0. Model named lenet_1509755228.\n"
     ]
    }
   ],
   "source": [
    "from ecbm4040.neuralnets.kaggle import my_training\n",
    "tf.reset_default_graph()\n",
    "my_training(X_train_rn, y_train_rn, X_val_rn, y_val_rn, \n",
    "         conv_featmap=[256, 64],\n",
    "         fc_units=[1024],\n",
    "         conv_kernel_size=[5, 5],\n",
    "         pooling_size=[2, 2],\n",
    "         l2_norm=0.01,\n",
    "         seed=235,\n",
    "         learning_rate=0.001,\n",
    "         epoch=20,\n",
    "         batch_size=245,\n",
    "         verbose=False,\n",
    "         pre_trained_model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = []\n",
    "extension = \".png\"\n",
    "#path_to_image_folder = ''#Wherever you have your images\n",
    "num_test_samples = 3500 #Ideally you could count the elements in the folder\n",
    "img_names = [str(idx)+extension for idx in range(num_test_samples)]\n",
    "#print(img_names)\n",
    "for img in img_names:\n",
    "    file_path = test_path + '/' + img\n",
    "    img = Image.open(file_path)\n",
    "    X_test.append(imresize(np.array(img), (32,32,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save your best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from model/lenet_1509755228\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "from ecbm4040.neuralnets.cnn_jupyter_tensorboard import show_graph \n",
    "tf.reset_default_graph()\n",
    "\n",
    "with tf.Session() as sess: \n",
    "    saver = tf.train.import_meta_graph('model/lenet_1509755228.meta')\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('model/'))\n",
    "    graph = tf.get_default_graph()\n",
    "\n",
    "    idx = 0\n",
    "    tf_input = graph.get_operations()[idx].name+':0'\n",
    "    x = graph.get_tensor_by_name(tf_input)\n",
    "    # Same procedure for y\n",
    "    tf_output = \"evaluate/ArgMax:0\"\n",
    "    y = graph.get_tensor_by_name(tf_output)\n",
    "    # Make prediciton\n",
    "    y_out = sess.run(y, feed_dict={x: X_test[:]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate .csv file for Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# The following code snippet can be used to generate your prediction .csv file.\n",
    "\n",
    "import csv\n",
    "with open('predicted.csv','w') as csvfile:\n",
    "    fieldnames = ['Id','label']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "    writer.writeheader()    \n",
    "    for index,l in enumerate(y_out):\n",
    "        filename = str(index)+'.png'\n",
    "        label = str(l)\n",
    "        writer.writerow({'Id': filename, 'label': label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
